{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divisive Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.75)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical clustering leads to a hierarchy of clusters. Two major types of hierarchical clustering algorithms are agglomerative and divisive. The former one starts with every data point in its own cluster and gradually merges cluters in a \"bottom-up\" fashion; the latter one assumes that all data points are in the same cluster initially and gradually divides it in a \"top-down\" fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This DivisiveCluster algorithm implements hierarchical clustering in a “divisive” approach based on a chosen clustering algorithm such as [AutoGMM](./autogmm.ipynb). It retrieves predictions on the full dataset from the chosen clustering algorithm, say AutoGMM, and passes each subset of data corresponding to a predicted cluster onto AutoGMM again while specifying min_components=1. If the best model computed by AutoGMM for any predicted cluster leads to more than one subcluster, each of the subclusters will be clustered recursively as described above; otherwise, that subcluster becomes a leaf cluster. The algorithm terminates when all branches of recursive clustering have led to a set of leaf clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using DivisiveCluster on Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following synthetic hierarchical data made up of two levels of four Gaussian distributions in 2D. The 4 distributions have the same standard deviation. And their means are chosen so that the difference between the first two is the same as that between the last two. Hence, this dataset can be classified into 4 clusters of 1 Gaussian component or 2 clusters of Gaussian mixtures of 2 components. Those are the two clustering hierarchies of increasing granularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate synethetic data\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "n = 100  # number of data points\n",
    "d = 2  # number of dimensions\n",
    "\n",
    "# Let Xij denote the ith Gaussian mixture component in the jth cluster at the lowest hierarchy, i.e., level 2\n",
    "X11 = np.random.normal(-4.5, 0.5, size=(n, d))\n",
    "X21 = np.random.normal(-3, 0.5, size=(n, d))\n",
    "X12 = np.random.normal(3, 0.5, size=(n, d))\n",
    "X22 = np.random.normal(4.5, 0.5, size=(n, d))\n",
    "X = np.vstack((X11, X21, X12, X22))\n",
    "\n",
    "# true label at either level\n",
    "y_lvl1 = np.repeat([0, 1], 2 * n).reshape((-1, 1))\n",
    "y_lvl2 = np.repeat([0, 1, 2, 3], n).reshape((-1, 1))\n",
    "y = np.hstack((y_lvl1, y_lvl2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting function for clustering\n",
    "def plot(X, y, title):\n",
    "    df = pd.DataFrame(np.hstack((X,y)))\n",
    "    df.columns = [\"dim1\", \"dim2\", \"level1\", \"level2\"]\n",
    "    df[\"level1\"] = df[\"level1\"].astype(int)\n",
    "    df[\"level2\"] = df[\"level2\"].astype(int)\n",
    "    fig,ax = plt.subplots(1, figsize=(10,10))\n",
    "    sns.scatterplot(\n",
    "        data=df, x=df[\"dim1\"], y=df[\"dim2\"], style=df[\"level1\"], hue=df[\"level2\"], palette=\"deep\", ax=ax, legend=False\n",
    "    )\n",
    "    ax.set(xticks=[], yticks=[], title=title)\n",
    "    plt.show()\n",
    "\n",
    "plot(X, y, \"True Clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.cluster import DivisiveCluster\n",
    "\n",
    "# fit model and predict on data\n",
    "dc = DivisiveCluster(max_components=2, cluster_method=\"gmm\", max_level=2)\n",
    "# choose to return a set of flat clusterings\n",
    "pred = dc.fit_predict(X, fcluster=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize clustering assignments for both levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.plot import pairplot_with_gmm\n",
    "\n",
    "pairplot_with_gmm(X[np.argsort(pred[:,0])], dc.model_, title=\"Clustering Assignments at Level 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For level-2 assignments, we will make a Gaussian Mixture model which has 4 components, corresponding to the 4 leaf clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reformat attributes of a Gaussian Mixture model such as \"covarainces_\"\n",
    "def reformat_attr(gmm, gmm_attr, n_features):\n",
    "    n_components = gmm.n_components\n",
    "    if gmm.covariance_type == \"tied\":\n",
    "        param = np.repeat(\n",
    "            gmm_attr[np.newaxis, :, :], n_components, axis=0\n",
    "        )\n",
    "    elif gmm.covariance_type == \"diag\":\n",
    "        param = np.array([\n",
    "            np.diag(gmm_attr[i]) for i in range(n_components)\n",
    "        ])\n",
    "    elif gmm.covariance_type == \"spherical\":\n",
    "        param = np.array([\n",
    "            np.diag(np.repeat(gmm_attr[i], n_features))\\\n",
    "                for i in range(n_components)\n",
    "        ])\n",
    "    else:\n",
    "        param = gmm_attr\n",
    "        \n",
    "    return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# collect key attributes of the leaf clusters\n",
    "n_features = 2\n",
    "n_clusters = 4\n",
    "means = np.empty((1, n_features))\n",
    "covs = np.empty((1, n_features, n_features))\n",
    "prec_chols = np.empty((1, n_features, n_features))\n",
    "for n_comp in range(n_clusters):\n",
    "    means = np.vstack((means, dc.leaves[n_comp].model_.means_))\n",
    "    cov = reformat_attr(dc.leaves[n_comp].model_, dc.leaves[n_comp].model_.covariances_, n_features)\n",
    "    covs = np.vstack((covs, cov))\n",
    "    prec_chol = reformat_attr(dc.leaves[n_comp].model_, dc.leaves[n_comp].model_.precisions_cholesky_, n_features)\n",
    "    prec_chols = np.vstack((prec_chols, prec_chol))\n",
    "\n",
    "means = means[1:, :]\n",
    "covs = covs[1:, :]\n",
    "prec_chols = prec_chols[1:, :]\n",
    "\n",
    "# generate a new Gaussian Mixture model made up of 4 components\n",
    "dc_gmm = GaussianMixture()\n",
    "dc_gmm.means_ = means\n",
    "dc_gmm.covariances_ = covs\n",
    "dc_gmm.precisions_cholesky_ = prec_chols\n",
    "dc_gmm.weights_ = np.repeat(1/n_clusters, n_clusters)\n",
    "dc_gmm.n_components = n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairplot_with_gmm(X[np.argsort(pred[:,1])], dc_gmm, title=\"Clustering Assignments at Level 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate clustering performance in terms of Adjusted Rand Index (ARI)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARI is in the range of 0 to 1 where a score of 1 means the predicted assignments are identical to the true ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "print(\"ARI score for model at level 1: %.2f\" % adjusted_rand_score(y[:,0], pred[:,0]))\n",
    "print(\"ARI score for model at level 2: %.2f\" % adjusted_rand_score(y[:,1], pred[:,1]))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}